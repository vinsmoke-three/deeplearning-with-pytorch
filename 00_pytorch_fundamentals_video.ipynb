{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a46c2d",
   "metadata": {},
   "source": [
    "## 00. Pytorch Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f206bf7",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "### Creating ternsor\n",
    "\n",
    "Pytorch tensors are created using torch.tensor() = https://docs.pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec741a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mpsが利用されているかを確認\n",
    "# 期待値　tensor([1.], device='mps:0')\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4fa4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# scalar 1 つの数字\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar.ndim)\n",
    "# 単一の値を含むテンソルからPythonの数値を取得するために使用します\n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9609afc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector 方向を持つ数値 (例: 風速と方向) ですが、他の多くの数値を持つこともできます\n",
    "vector = torch.tensor([7, 7])\n",
    "vector.ndim, vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91c7d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [2, 4]])\n",
      "2\n",
      "torch.Size([2, 2])\n",
      "tensor([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Matrix 数値の 2 次元配列\n",
    "# 大文字は一般的です\n",
    "MATRIX = torch.tensor([[1, 3],\n",
    "                       [2, 4]])\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)\n",
    "print(MATRIX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e318c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [3, 4, 5],\n",
      "         [5, 6, 7]]])\n",
      "3\n",
      "torch.Size([1, 3, 3])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# Tensor 数値の n 次元配列\n",
    "# 大文字は一般的です\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 4, 5],\n",
    "                        [5, 6, 7]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR[0][1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9287bc4",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "Why random tensors?\n",
    "\n",
    "PyTorch を使用して機械学習モデルを構築する場合、テンソルを手作業で作成することはめったにありません (私たちが行ってきたように)。\n",
    "\n",
    "代わりに、機械学習モデルは多くの場合、数値の大きなランダムなテンソルから開始し、データを介してこれらの乱数を調整して、データをより適切に表現します。\n",
    "\n",
    "データ サイエンティストは、機械学習モデルの開始方法 (初期化)、データの表示方法、乱数の更新 (最適化) を定義できます。\n",
    "\n",
    "Torch random tensors - https://docs.pytorch.org/docs/main/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f36e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6824, 0.4339, 0.7100, 0.4324],\n",
       "         [0.1593, 0.0316, 0.4038, 0.4528],\n",
       "         [0.5886, 0.0108, 0.5766, 0.2656]]),\n",
       " 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor, random_tensor.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c229f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3, 224, 224)) # R, G ,B\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c7639",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34feecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros((3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b27ae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32,\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all ones\n",
    "ones = torch.ones((3, 4))\n",
    "ones.dtype, ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8497ca",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d2e9217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/tvcjtl9x42jdg7mfpg1_w0j80000gn/T/ipykernel_46746/3498912548.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range(0, 10)\n",
    "torch.range(0, 10)\n",
    "torch.arange(0, 10)\n",
    "one_to_ten = torch.arange(start=1, end=10, step=2)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48705ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16976ae",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "[PyTorch には、さまざまなテンソルデータ型があります。](https://docs.pytorch.org/docs/stable/tensors.html#data-types)\n",
    "\n",
    "CPUに固有のものもあれば、GPUに適したものもあります。\n",
    "\n",
    "どちらがいいかを知るには、時間がかかることがあります。\n",
    "\n",
    "通常、どこかで torch.cuda を見かけると、テンソルが GPU に使用されています (Nvidia GPU は CUDA と呼ばれるコンピューティングツールキットを使用しているため)。\n",
    "\n",
    "最も一般的な型 (そして一般的にはデフォルト) は torch.float32 または torch.float です。\n",
    "\n",
    "これは「32ビット浮動小数点」と呼ばれます。\n",
    "\n",
    "ただし、16 ビット浮動小数点 (torch.float16 または torch.half) と 64 ビット浮動小数点 (torch.float64 または torch.double) もあります。\n",
    "\n",
    "さらに混乱させるのは、8ビット、16ビット、32ビット、64ビットの整数です。\n",
    "\n",
    "さらに、もっと!\n",
    "\n",
    "手記：整数は 7 のような平らな丸い数ですが、浮動小数点数の小数は 7.0 です。\n",
    "\n",
    "これらすべての理由は、コンピューティングの精度に関係しています。\n",
    "\n",
    "精度は、数値を説明するために使用される詳細の量です。\n",
    "\n",
    "精度の値 (8、16、32) が高いほど、数値の表現に使用されるデータの詳細度が高くなります。\n",
    "\n",
    "ディープラーニングや数値計算では、非常に多くの演算を行うため、計算する詳細度が高ければ高いほど、より多くの計算を使用する必要があるため、これは重要です。\n",
    "\n",
    "そのため、精度の低いデータ型は一般的に計算が高速になりますが、精度などの評価メトリックのパフォーマンスが一部犠牲になります (計算は高速ですが、精度は低くなります)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6246a6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], device='mps:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 4.0, 5.0],\n",
    "                                dtype=torch.float32,  # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                                device=\"mps\", # defaults to None, which uses the default tensor type\n",
    "                                requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a7a9f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eca8f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 16., 25.], device='mps:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568460aa",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "- 形状 - テンソルの形状は何ですか?(一部の操作には特定の形状ルールが必要です)\n",
    "- dtype - テンソル内の要素はどのデータ型に格納されていますか?\n",
    "- デバイス - テンソルはどのデバイスに格納されていますか?(通常はGPUまたはCPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc514bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1515, 0.4290, 0.8059, 0.6290],\n",
      "        [0.3464, 0.7190, 0.4837, 0.6463],\n",
      "        [0.9553, 0.6466, 0.0363, 0.1495]])\n",
      "Datatype of tensor: torch.float32\n",
      "torch.Size([3, 4])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(some_tensor.shape)\n",
    "print(some_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606f3fd",
   "metadata": {},
   "source": [
    "## テンソルの操作(テンソル演算)\n",
    "* 足し算\n",
    "* 減算\n",
    "* 乗算(要素ごと)\n",
    "* 除法\n",
    "* 行列の乗算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7d8250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 13, 15])\n",
      "tensor([-9, -7, -5])\n",
      "tensor([10, 30, 50])\n",
      "tensor([0.1000, 0.3000, 0.5000])\n",
      "tensor([10, 30, 50])\n",
      "tensor([11, 13, 15])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 3, 5])\n",
    "print(tensor + 10)\n",
    "print(tensor - 10)\n",
    "print(tensor * 10)\n",
    "print(tensor / 10)\n",
    "print(torch.mul(tensor, 10))\n",
    "print(torch.add(tensor, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f2277",
   "metadata": {},
   "source": [
    "### 行列の乗算(Matrix multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e34245c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1*1 + 2*2 + 3*3\n",
    "# Matrix multiplication\n",
    "# 2つの1Dベクトル(shape = (3,))がtorch.matmulに渡されると、\n",
    "# PyTorchは自動的にそれらをベクトルのドット積として解釈し、\n",
    "# これはNumPyのnp.dotの動作と一致します。\n",
    "tensor_a = torch.tensor([1, 2, 3])\n",
    "tensor_b = torch.tensor([1, 2, 3])\n",
    "torch.matmul(tensor_a, tensor_b)\n",
    "# torch.mm(tensor_a, tensor_b)\n",
    "# tensor_a @ tensor_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c42df3",
   "metadata": {},
   "source": [
    "### 深層学習で最も一般的なエラーの 1 つ (形状エラー)\n",
    "ディープラーニングの多くは乗算と行列に対する演算の実行であり、行列には組み合わせることができる形状とサイズについて厳密なルールがあるため、ディープラーニングで遭遇する最も一般的なエラーの 1 つは形状の不一致です。\n",
    "\n",
    "1. 内側の寸法は、次のものと一致する必要があります。\n",
    "* (3, 2) @ (3, 2) が機能しない\n",
    "* (2, 3) @ (3, 2) が機能します\n",
    "* (3, 2) @ (2, 3) が機能します\n",
    "2. 結果の行列は、外形寸法の形状になります。\n",
    "* (2, 3) @ (3, 2) -> (2, 2)\n",
    "* (3, 2) @ (2, 3) -> (3, 3)\n",
    "\n",
    "> **Note** http://matrixmultiplication.xyz/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab6a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "# torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e09e3",
   "metadata": {},
   "source": [
    "\n",
    "行列の乗算をtensor_Aとtensor_Bの間で機能させるには、それらの内部寸法を一致させます。\n",
    "\n",
    "これを行う方法の1つは、転置(特定のテンソルの次元を切り替える)を使用することです。\n",
    "\n",
    "PyTorch では、次のいずれかを使用して転置を実行できます。\n",
    "\n",
    "* torch.transpose(input, dim0, dim1) - ここで、input は転置する目的のテンソルで、dim0 と dim1 はスワップする次元です。\n",
    "* tensor_B.T - ここで、tensor は転置する目的のテンソルです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "995fc711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(tensor_A, tensor_B.T))\n",
    "\n",
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ceeee",
   "metadata": {},
   "source": [
    "### 最小、最大、平均、合計などの検索(集計)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e5aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) torch.int64\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(90)\n",
      "tensor(90)\n",
      "tensor(45.)\n",
      "tensor(450)\n",
      "tensor(450)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "print(x, x.dtype)\n",
    "print(torch.min(x))\n",
    "print(x.min())\n",
    "print(torch.max(x))\n",
    "print(x.max())\n",
    "# torch.mean() などの一部のメソッドでは、テンソルが torch.float32 (最も一般的) \n",
    "# または別の特定のデータ型にある必要があり、そうしないと操作が失敗します。\n",
    "print(torch.mean(x.type(torch.float32)))\n",
    "print(torch.sum(x))\n",
    "print(x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a9d11ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# ポジショナル最小/最大\n",
    "print(x.argmax())\n",
    "print(x.argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081e984",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing\n",
    "\n",
    "|Method|One-line description|\n",
    "|-|-|\n",
    "|torch.reshape(input, shape)\t|Reshapes input to shape (if compatible), can also use torch.Tensor.reshape().|\n",
    "|Tensor.view(shape)\t|Returns a view of the original tensor in a different shape but shares the same data as the original tensor.|\n",
    "|torch.stack(tensors, dim=0)\t|Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.|\n",
    "|torch.squeeze(input)\t|Squeezes input to remove all the dimenions with value 1.|\n",
    "|torch.unsqueeze(input, dim)\t|Returns input with a dimension value of 1 added at dim.|\n",
    "|torch.permute(input, dims)\t|Returns a view of the original input with its dimensions permuted (rearranged) to dims.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ba8252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]) torch.Size([9])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]]) torch.Size([3, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]]) torch.Size([3, 3])\n",
      "tensor([[5., 2., 3.],\n",
      "        [5., 5., 6.],\n",
      "        [5., 8., 9.]]) tensor([5., 2., 3., 5., 5., 6., 5., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1., 10.)\n",
    "print(x, x.shape)\n",
    "\n",
    "# add an extra dimension\n",
    "# x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped = x.reshape(3, 3)\n",
    "print(x_reshaped, x_reshaped.shape)\n",
    "\n",
    "# change the view\n",
    "z = x.view(3, 3)\n",
    "print(z, z.shape)\n",
    "\n",
    "# change z changes x ,viewが変更されたら、xも変更される。メモリアドレスは同じだから\n",
    "z[:, 0] = 5\n",
    "print(z, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3feca5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 2., 3., 5., 5., 6., 5., 8., 9.])\n",
      "tensor([[5., 5.],\n",
      "        [2., 2.],\n",
      "        [3., 3.],\n",
      "        [5., 5.],\n",
      "        [5., 5.],\n",
      "        [6., 6.],\n",
      "        [5., 5.],\n",
      "        [8., 8.],\n",
      "        [9., 9.]]) torch.Size([9, 2])\n"
     ]
    }
   ],
   "source": [
    "# stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x], dim = 1)\n",
    "print(x)\n",
    "print(x_stacked, x_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0bb0172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]]) torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# squeeze tensors\n",
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "x_squeeze = torch.squeeze(x)\n",
    "print(x_squeeze, x_squeeze.size())\n",
    "# x_squeeze = torch.squeeze(x, 0)\n",
    "# print(x_squeeze, x_squeeze.size())\n",
    "# x_squeeze = torch.squeeze(x, 1)\n",
    "# print(x_squeeze, x_squeeze.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0e44972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "previous shape: torch.Size([2, 2, 2])\n",
      "tensor([[[[0., 0.],\n",
      "          [0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.],\n",
      "          [0., 0.]]]]) torch.Size([2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze()\n",
    "print(f\"Previous target: {x_squeeze}\")\n",
    "print(f\"previous shape: {x_squeeze.shape}\")\n",
    "\n",
    "x_unsqueezed = x_squeeze.unsqueeze(dim=1)\n",
    "print(x_unsqueezed, x_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dfe0133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([224, 224, 3])\n",
      "tensor(2222.) tensor(2222.)\n"
     ]
    }
   ],
   "source": [
    "# torch.permute()\n",
    "# Returns a view of the original input with its dimensions permuted (rearranged) to dims.\n",
    "# viewを返す\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "x_permeted = torch.permute(x_original, (2, 0, 1))\n",
    "print(x_permeted.shape)\n",
    "print(x_original.shape)\n",
    "\n",
    "# 同じメモリアドレスだから\n",
    "# x_original[0, 0 ,0] = 111111\n",
    "x_permeted[0, 0 ,0] = 2222\n",
    "\n",
    "print(x_original[0, 0, 0], x_permeted[0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f883e3a",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aa94b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(1)\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([[1, 4, 7]])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "print(x, x.shape)\n",
    "\n",
    "# Let's index on our new tensor\n",
    "print(x[0])\n",
    "print(x[0][0])\n",
    "print(x[0][0][0])\n",
    "\n",
    "# you can also use \":\" to select all of a target dimension\n",
    "print(x[:, 0, :])\n",
    "print(x[:, :, 0])\n",
    "\n",
    "# get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "print(x[:, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d379a2e",
   "metadata": {},
   "source": [
    "## pytorch tensors and numpy\n",
    "NumPyは人気のあるPython数値計算ライブラリであるため、PyTorchにはそれをうまく操作する機能があります。\n",
    "\n",
    "NumPy から PyTorch への (およびその逆) に使用する主な 2 つの方法は次のとおりです。\n",
    "\n",
    "* Data in numpy, want in pytorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* Pytorch tensor -> numpy -> `torch.tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c87c9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.]) torch.float32\n",
      "[10. 20. 30. 40. 50. 60. 70.] tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1. 1. 1. 1.] float32\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10.]) [1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from numpy import dtype\n",
    "import numpy\n",
    "\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "print(array.dtype)\n",
    "print(array, tensor, tensor.dtype)\n",
    "\n",
    "# change the value of array, what will this do to `tensor`\n",
    "array = array * 10\n",
    "print(array, tensor)\n",
    "\n",
    "# tensor to numpy array\n",
    "tensor = torch.ones(8)\n",
    "numpy_tensor = tensor.numpy()\n",
    "print(tensor, numpy_tensor, numpy_tensor.dtype)\n",
    "\n",
    "# change the tensor, what hanppens to `numpy_tensor`\n",
    "tensor = tensor * 10\n",
    "print(tensor, numpy_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e195cce",
   "metadata": {},
   "source": [
    "## Reproducbility (trying to take random out of random)\n",
    "再現性(ランダムからランダムを取り除こうとする)\n",
    "\n",
    "ランダム性は素晴らしく強力ですが、ランダム性を少し減らしたい場合があります。\n",
    "\n",
    "なぜでしょうか。\n",
    "\n",
    "そのため、反復可能な実験を行うことができます。\n",
    "\n",
    "たとえば、X パフォーマンスを達成できるアルゴリズムを作成するとします。\n",
    "\n",
    "そして、あなたの友人はそれを試してみて、あなたが狂っていないことを確認します。\n",
    "\n",
    "どうしてそんなことができるのだろう?\n",
    "\n",
    "そこで、再現性の出番です。\n",
    "\n",
    "言い換えれば、私が私のコンピュータで得るのと同じコードを実行しているあなたのコンピュータで同じ(または非常によく似た)結果を得ることができますか?\n",
    "\n",
    "PyTorch での再現性の簡単な例を見てみましょう。\n",
    "\n",
    "まず、2つのランダムなテンソルを作成しますが、それらはランダムであるため、異なると予想されますよね?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac29b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4391, 0.6196, 0.7505, 0.7156],\n",
      "        [0.9042, 0.2950, 0.4127, 0.0252],\n",
      "        [0.5446, 0.3252, 0.6805, 0.1873]])\n",
      "tensor([[0.2874, 0.8757, 0.1099, 0.1557],\n",
      "        [0.6750, 0.5061, 0.6277, 0.4129],\n",
      "        [0.6435, 0.6629, 0.5479, 0.1246]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aceb24",
   "metadata": {},
   "source": [
    "ご想像のとおり、テンソルは異なる値で出力されます。\n",
    "\n",
    "しかし、同じ値を持つ 2 つのランダムなテンソルを作成する場合はどうでしょうか。\n",
    "\n",
    "同様に、テンソルにはまだランダムな値が含まれていますが、それらは同じフレーバーになります。\n",
    "\n",
    "そこで登場するのがtorch.manual_seed(seed)で、seedはランダム性を風味づける整数(42などですが、何でもかまいません)です。\n",
    "\n",
    "もう少し風味豊かなランダムテンソルを作成して試してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42dc01c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da4c72",
   "metadata": {},
   "source": [
    "## GPUでテンソルを実行する(および計算を高速化する)\n",
    "### PyTorchをGPU上で動作させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf236fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device type\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93742792",
   "metadata": {},
   "source": [
    "### PyTorch を Apple Silicon で動作させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "002a84d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# set device type\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1a7cd",
   "metadata": {},
   "source": [
    "### GPU にテンソル (およびモデル) を配置する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93e8789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n",
      "tensor([1, 2, 3], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# create tensor\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# move tensor to gpu\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218d5ca",
   "metadata": {},
   "source": [
    "### テンソルを CPU に戻す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d20f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# NumPy は GPU を活用しません\n",
    "# tensor_on_gpu.numpy() # error\n",
    "\n",
    "# 代わりに、テンソルをCPUに戻し、\n",
    "# NumPyで使用できるようにするには、 Tensor.cpu() を使用できます。\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "print(tensor_back_on_cpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
